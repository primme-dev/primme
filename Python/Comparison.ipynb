{
 "cells": [
  {
   "source": [
    "Primme Performance Comparison \n",
    "=============================\n",
    "All tests run on a Ryzen 2700X with 32GB of RAM available"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7878de58-ba7d-4d96-b8b5-2ff139168d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.9\n"
     ]
    }
   ],
   "source": [
    "#!pip install primme sklearn\n",
    "#!pip install -e git+https://github.com/bwlewis/irlbpy.git#egg=irlbpy\n",
    "#!pip install -e git+https://github.com/jakevdp/pypropack.git#egg=pypropack\n",
    "#!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8936d41d-793f-434e-ab73-a44fb973ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import primme, irlb, timeit, sklearn.decomposition, scipy.sparse, numpy as np\n",
    "from tabulate import tabulate\n",
    "#from pypropack import svdp\n",
    "\n"
   ]
  },
  {
   "source": [
    "PRIMME eigsh is based on Davidson-type methods and they may be faster than Lanczos/Arnoldi based method in difficult problems that eigenpairs take many iterations to converge or an efficient preconditioner is available.l"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd2f462-dac5-4713-8d1a-09bace5eafa9",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================  =======  ========  ========\ntest                        time  matvec       rnorm\n=======================  =======  ========  ========\nPrimme                    36.922  568       0.120693\nsp.sparse.linalg.lobpcg  126.848  ---       0.115554\n=======================  =======  ========  ======== \n\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "#EigenValue Tests\n",
    "#------------------------\n",
    "\n",
    "normA = 12000\n",
    "headers = [\"test\", \"time\", \"matvec\", \"rnorm\"]\n",
    "\n",
    "table = list()\n",
    "tolerance = 1e-5\n",
    "A = np.diag(np.asarray(range(1,12001), dtype=np.float32), 0)\n",
    "for i in range(1,11999):\n",
    "  A[i,i+1] = 1\n",
    "  A[i+1,i] = 1\n",
    "\n",
    "#PRIMME performance test\n",
    "start = timeit.default_timer()\n",
    "evals, evecs, stats = primme.eigsh(A, 2, tol=tolerance, return_stats =True, return_history=True)\n",
    "end = timeit.default_timer()\n",
    "table.append([\"Primme\", end - start, stats[\"numMatvecs\"], max(stats['rnorms'])])\n",
    "\n",
    "#scipy.sparse.linalg.lobpcg performance test\n",
    "y = np.eye(12000, 2)\n",
    "rng = np.random.default_rng()\n",
    "X = rng.random((12000, 2))\n",
    "start = timeit.default_timer()\n",
    "evals, evecs = scipy.sparse.linalg.lobpcg(A, X=X, tol=tolerance*normA, largest=True, maxiter=1000)\n",
    "end = timeit.default_timer()\n",
    "rnorm = np.linalg.norm(np.matmul(A, evecs) - (evecs.dot(np.diag(evals))), axis=0)\n",
    "table.append([\"sp.sparse.linalg.lobpcg\", end - start, \"---\", max(rnorm)])\n",
    "print(tabulate(table, headers=headers, tablefmt=\"rst\"), \"\\n\")\n"
   ]
  },
  {
   "source": [
    "By default PRIMME tries to guess the best configuration, but a little hint can help sometimes. Convergence can be accelerated by providing PRIMME with a preconditioner "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142fc817-9f67-4e26-ab90-b57f55fe55c4",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========  ========  ========  ========\ntest             time    matvec     rnorm\n===========  ========  ========  ========\nPrimme       36.6693        458  0.118197\nPrimme Prec   1.94905        29  0.108924\n===========  ========  ========  ======== \n\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------\n",
    "#EigenValue Preconditioner comparison Tests\n",
    "#------------------------------------------\n",
    "\n",
    "table = list()\n",
    "#PRIMME performance test\n",
    "start = timeit.default_timer()\n",
    "evals, evecs, stats = primme.eigsh(A, 2, which= 'SM', tol=tolerance, return_stats =True, return_history=True)\n",
    "end = timeit.default_timer()\n",
    "table.append([\"Primme\", end - start, stats[\"numMatvecs\"], max(stats['rnorms'])])\n",
    "\n",
    "\n",
    "diagInv = np.diag(np.reciprocal(np.asarray(range(1,12001), dtype=np.float32)), 0)\n",
    "#PRIMME Preconditioned performance test\n",
    "start = timeit.default_timer()\n",
    "evals, evecs, stats = primme.eigsh(A, 2, OPinv= diagInv, tol=tolerance, return_stats =True, which= 'SM', return_history=True)\n",
    "end = timeit.default_timer()\n",
    "table.append([\"Primme Prec\", end - start, stats[\"numMatvecs\"], max(stats['rnorms'])])\n",
    "print(tabulate(table, headers=headers, tablefmt= \"rst\"), \"\\n\")\n"
   ]
  },
  {
   "source": [
    "For svds problems the package has a similar intereface. PRIMME svds may perform as good as similar methods in the packages scipy.linalg.sparse and irlb in solving few singular values. PRIMME can take advantage of a light matrix-vector product. For larger problems PRIMME performs similarly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f72ca17-a981-44cc-81ae-30fca1764321",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=====================  =========  ========  ======================\n",
      "test                        time  matvec    rnorm\n",
      "=====================  =========  ========  ======================\n",
      "Primme                  10.3734   546       0.0007492027131764414\n",
      "sp.sparse.linalg.svds    5.81644  ---       4.2308075210909703e-10\n",
      "irlb                     5.35749  ---       0.0011904085013419677\n",
      "sklearn                154.079    ---       ---\n",
      "=====================  =========  ========  ====================== \n",
      "\n",
      "=====================  =======  ========  ===========\n",
      "test                      time  matvec          rnorm\n",
      "=====================  =======  ========  ===========\n",
      "Primme                 29.0386  6052      0.00212599\n",
      "sp.sparse.linalg.svds  34.1852  ---       1.39758e-13\n",
      "irlb                   39.979   ---       0.00154099\n",
      "=====================  =======  ========  =========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "#Singular Value Tests\n",
    "#------------------------\n",
    "\n",
    "A = np.random.normal(size=(6000,6000))\n",
    "normA = 154.8\n",
    "k = [2,100]\n",
    "\n",
    "for n in k:\n",
    "  table = list()\n",
    "  #PRIMME performance test\n",
    "  #Because A is a dense matrix we use a large maxBlockSize to take advantage of BLAS3.\n",
    "  #For sparse matirices much smaller maxBlockSize. Experiment based on you problem.\n",
    "  start = timeit.default_timer()\n",
    "  u, sdvals, vt, stats = primme.svds(A, n, tol=tolerance, maxBlockSize=n, return_stats=True)\n",
    "  end = timeit.default_timer()\n",
    "  table.append([\"Primme\", end - start, stats[\"numMatvecs\"], max(stats['rnorms'])])\n",
    "  \n",
    "  #scipy.sparse.linalg.svds performance test\n",
    "  start = timeit.default_timer()\n",
    "  u, sdvals, vt = scipy.sparse.linalg.svds(A, n, tol=tolerance*normA, return_singular_vectors=True)\n",
    "  end = timeit.default_timer()\n",
    "  rnorm = np.linalg.norm(A.dot(vt.T.conj()) - u.dot(np.diag(sdvals)),axis=0)**2+np.linalg.norm( u.T.conj().dot(A).T.conj() -(vt.T.conj()).dot(np.diag(sdvals)), axis=0)**2\n",
    "  table.append([\"sp.sparse.linalg.svds\", end - start, \"---\", max(rnorm)])\n",
    "  \n",
    "  #irlb performance test\n",
    "  start = timeit.default_timer()\n",
    "  u, sdvals, v, it, mprod  = irlb.irlb(A, n, tol=tolerance, maxit = 1000)\n",
    "  end = timeit.default_timer()\n",
    "  rnorm = np.linalg.norm(A.dot(v) - u.dot(np.diag(sdvals)),axis=0)**2+np.linalg.norm( u.T.conj().dot(A).T.conj() -v.dot(np.diag(sdvals)), axis=0)**2\n",
    "  table.append([\"irlb\", end - start, \"---\", max(np.sqrt(rnorm))])\n",
    "  \n",
    "  if n == 2:\n",
    "    #sklearn.decomposition permormance test\n",
    "    start = timeit.default_timer()\n",
    "    svdals = sklearn.decomposition.TruncatedSVD(n_components= n, tol=tolerance, n_iter = 1000)\n",
    "    svdals.fit(A)\n",
    "    end = timeit.default_timer()\n",
    "    table.append([\"sklearn\", end - start, '---', '---'])\n",
    "  print(tabulate(table, headers=headers, tablefmt=\"rst\"), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}